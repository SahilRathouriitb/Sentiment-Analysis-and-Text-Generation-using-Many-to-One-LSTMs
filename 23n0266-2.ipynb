{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "Yeah ! Let's start with our actual project. In this assignment we will load the database and do preprocessing tasks.\n",
    "Ensure you have following packages installed\n",
    "1. numpy\n",
    "2. pandas  \n",
    "( Hope you are familiar with above two modules well )\n",
    "3. nltk (don't worry, we just need this to remove stopwords while preprocessing)\n",
    "4. tensorflow\n",
    "5. keras\n",
    "6. scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importing essential libraries and functions\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the IMDB Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "df=pd.read_csv('C:\\\\Users\\\\DELL\\\\Downloads\\\\IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# 50000 rows and 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "# no missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Complete the function to preprocess the text data\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    sentence=sentence.lower() # First make the sentence lowercase\n",
    "    sentence=re.sub(r'<[^>]+>',' ',sentence) # Remove all html tags from the sentence i.e replace anything between <> with space\n",
    "    sentence=re.sub(r'[^a-zA-Z0-9]',' ',sentence)     # Remove all special characters i.e. anything other than alphabets and numbers. Replace them with space\n",
    "    sentence=re.sub(r'\\b[a-zA-Z]\\b',' ',sentence) # Remove all single characters i.e. a-z and A-Z and Replace them with space\n",
    "    sentence=re.sub(r'\\s+',' ',sentence) # Remove all multiple spaces and replace them with single space\n",
    "    # Use the nltk library to remove all stopwords from the sentence\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentence = word_tokenize(sentence)\n",
    "    filtered_words = [i for i in sentence if i.lower() not in stop_words]\n",
    "    cleaned_sentence = ' '.join(filtered_words)\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sahil boy\n"
     ]
    }
   ],
   "source": [
    "print(preprocessing('SAHIL IS A <****> BOY !?!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO :\n",
    "# Call the preprocessing function for each review in the dataframe and\n",
    "# save the results in a new list of preprocessed_reviews\n",
    "preprocessed_reviews=[]\n",
    "for i in range(0,df.shape[0]):\n",
    "    list=df['review'].tolist()\n",
    "    text=list[i]\n",
    "    text=preprocessing(text)\n",
    "    preprocessed_reviews.append(text)\n",
    "    \n",
    "# This list will be your input to the neural network\n",
    "# We will call this list as X from now on\n",
    "X=preprocessed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO :\n",
    "\n",
    "df['sentiment']=df['sentiment'].replace({'positive':1,'negative':0})# Convert sentiment column in the dataframe to numbers\n",
    "y=np.array(df['sentiment'])# Convert positive to 1 and negative to 0 and store it in numpy array\n",
    "y=y.reshape(50000,1)\n",
    "# We will call this numpy array as y from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Split the data into training and testing (80-20 ratio)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.2)\n",
    "# The train set will be used to train our deep learning models \n",
    "# while test set will be used to evaluate how well our model performs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing embedding layer\n",
    "Let's now write the script for our embedding layer. Embedding layer converts our textual data into numeric form. It is then **used as the first layer for the deep learning model like LSTM**.  \n",
    "To know more about word embedding you may refer to following video\n",
    "https://www.youtube.com/watch?v=9S0-OC4LFNo  \n",
    "#### Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92181"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "word_tokenizer = Tokenizer()\n",
    "\n",
    "# TODO: Fit the tokenizer on the training data (X_train)\n",
    "word_tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# TODO: Convert training data to sequences of integers\n",
    "# Hint: Use texts_to_sequences method\n",
    "X_train_sequences = word_tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "# TODO: Convert test data to sequences of integers\n",
    "X_test_sequences = word_tokenizer.texts_to_sequences(X_test)\n",
    "# Hint: Use texts_to_sequences method\n",
    "\n",
    "# End TODO\n",
    "# Saving the tokenizer in a json file (Already done for you)\n",
    "# This will be used later for prediction on data in next assignments\n",
    "tokenizer_json = word_tokenizer.to_json()\n",
    "with io.open('b3_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "    \n",
    "# Vocab_length is the number of unique words in our dataset\n",
    "# Adding 1 to store dimensions for words for which no pretrained word embeddings exist\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding all reviews to be of same length 'maxlen' words\n",
    "maxlen = 100\n",
    "# You can try different dimensions like 50, 100, 200 and 300\n",
    "# and see how the model performs in next week\n",
    "\n",
    "# TODO: Pad the training data sequences\n",
    "X_train_pad=pad_sequences(X_train_sequences,padding='post',maxlen=100)\n",
    "# Hint: Use pad_sequences with 'post' padding and maxlen=maxlen\n",
    "\n",
    "# TODO: Pad the test data sequences\n",
    "X_test_pad=pad_sequences(X_train_sequences,padding='post',maxlen=100)\n",
    "# Hint: Use pad_sequences with 'post' padding and maxlen=maxlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary for embeddings\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "# Open the GloVe file (a2_glove.6B.100d.txt) with utf-8 encoding\n",
    "glove_file = open('C:\\\\Users\\\\DELL\\\\Desktop\\\\Sentiment Analysis_Soc\\\\glove_embeddings.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "# TODO : Create an embedding matrix where each row corresponds to the index of the unique word in the dataset and each column corresponds to the word vector in the GloVe embedding So the matrix will have vocab_length rows and maxlen columns\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.38251001,  0.14821   ,  0.60601002, ...,  0.058921  ,\n",
       "         0.091112  ,  0.47283   ],\n",
       "       [ 0.19915999, -0.049702  ,  0.24579   , ..., -0.068109  ,\n",
       "         0.017651  ,  0.06455   ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.47591999,  0.61685002, -0.14140999, ..., -0.1066    ,\n",
       "         0.11714   , -0.34955001]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
